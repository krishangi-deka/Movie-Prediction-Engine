{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieRecSystem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishangi-deka/Movie-Prediction-Engine/blob/main/MovieRecSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBuQctZdAg5O"
      },
      "source": [
        "# **Movie Recommender System - Using Spark**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WvaMEnMA5l2"
      },
      "source": [
        "Installing Spark and JDK and Setting environment variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5pgVcoOOeEK"
      },
      "source": [
        "%%sh\n",
        "apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "tar -xvf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00M6GvmoPkO-"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awJdokMgBCrB"
      },
      "source": [
        "Creating a local Spark Session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk9nN8hGPn7_"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession,SQLContext\n",
        "from pyspark.sql import functions as F\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfcecWP7BJ59"
      },
      "source": [
        "Mounting on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOLyf15BPp-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71820338-3279-414d-a7f8-f718e4907825"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZu3QMZQPu0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221b51e1-06bb-4e03-9aa0-13cbfb02b9ed"
      },
      "source": [
        "%cd /content/drive/Shared drives/IDS561/HW5\n",
        "#!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/IDS561/HW5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vflmr9QBgBH"
      },
      "source": [
        "## **STEP 1**\n",
        "Importing file and extracting columns to be used for Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcSmenI0ng11"
      },
      "source": [
        "data = spark.read.option(\"delimiter\", \"\\t\").csv(\"/content/drive/Shared drives/IDS561/HW5/u.data\").toDF(\"user_id\",\"item_id\", \"rating\", \"timestamp\")\n",
        "#data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggLbqmVoXFl6"
      },
      "source": [
        "df = data.drop('timestamp')  #keeping only the relevant columns for data processing.\n",
        "#df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekjoFxHT731y"
      },
      "source": [
        "#Converting data type from string to integer\n",
        "from pyspark.sql.types import IntegerType\n",
        "df = df.withColumn(\"user_id\", df[\"user_id\"].cast(IntegerType()))   \n",
        "df = df.withColumn(\"item_id\", df[\"item_id\"].cast(IntegerType()))    \n",
        "df = df.withColumn(\"rating\", df[\"rating\"].cast(IntegerType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT8gZpwu9gDh"
      },
      "source": [
        "df = df.sort(df.user_id.asc())  #data sorted by user_id\n",
        "#df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0XCokFCC7wl"
      },
      "source": [
        "## **STEP 2**\n",
        "Building a recommendation model using Alternating Least Squares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHMWtKSUSPMr"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLGpNvcwC4sB"
      },
      "source": [
        "#Create test and train set\n",
        "(train, test) = df. randomSplit([0.8, 0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC5By0aiQPXe"
      },
      "source": [
        "#Define evaluator as RMSE\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8cdK8M9C5iS"
      },
      "source": [
        "#Create ALS model\n",
        "als = ALS(userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\", nonnegative = True)\n",
        "model = als.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okt0sgjGC8uj"
      },
      "source": [
        "#Generate predictions\n",
        "pred = model.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5dDr9_mD1y-"
      },
      "source": [
        "## **STEP 3**\n",
        "Original RMSE Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjq_EmqiG9rV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5103eee1-b418-4124-bd00-5efc9579ebaf"
      },
      "source": [
        "#Evaluate using RMSE and print evaluation metrics \n",
        "rmse = evaluator.evaluate(pred)\n",
        "print(\"Root mean square error(RMSE) = \" + str(rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root mean square error(RMSE) = nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b5bGydoEvKv"
      },
      "source": [
        "## **STEP 4**\n",
        "Part 1: Solving the cold-start problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sGvGTVtRDlQ"
      },
      "source": [
        "#We got mean square error as nan because we did not solve the cold start problem.\n",
        "#What is a cold start problem? Cold-start problem refers to when the system cannot draw any inferences for users or items about which it has not \n",
        "#yet gathered sufficient information. \n",
        "\n",
        "#Retraining the ALS model\n",
        "als = ALS(userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\", coldStartStrategy = \"drop\", nonnegative = True)\n",
        "model = als.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd-QXh-GoH2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561bc307-7aff-4059-845e-7eb60d273dd5"
      },
      "source": [
        "#Print the new RMSE\n",
        "print(\"New RMSE = \", evaluator.evaluate(model.transform(test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New RMSE =  0.92067680707247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9QFWgzAob7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d6c5cd-f8ad-4a46-cd51-0c38c4ac61cd"
      },
      "source": [
        "#Print other model parameters\n",
        "print(\"Rank: \", model.rank)\n",
        "print(\"Max Iter: \", model._java_obj.parent().getMaxIter())\n",
        "print(\"Reg Param: \", model._java_obj.parent().getRegParam())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rank:  10\n",
            "Max Iter:  10\n",
            "Reg Param:  0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNRfv-nOFeSN"
      },
      "source": [
        "Part 2: Perform 10-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ99A_5Ro3DB"
      },
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "\n",
        "model = ALS(userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\", coldStartStrategy = \"drop\", nonnegative = True)\n",
        "\n",
        "#Tuning model with ParamGridBuilder\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(model.regParam, [0.05,0.1, 0.01, 0.001]) \\\n",
        "    .addGrid(model.rank, [5, 10, 15,20]) \\\n",
        "    .build()\n",
        "#print(param_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxpuf7jxpdOb"
      },
      "source": [
        "#Build a 10 fold cross validation\n",
        "crossvalidation = CrossValidator(estimator = model, estimatorParamMaps = param_grid, evaluator = evaluator, numFolds=10)\n",
        "\n",
        "#Fit ALS model to training data\n",
        "best_model = crossvalidation.fit(train).bestModel\n",
        "\n",
        "#Extract best model from the tuning exercise using ParamGridBuilder\n",
        "#best_model = model.bestModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzG513xvF-hP"
      },
      "source": [
        "## **STEP 5**\n",
        "RMSE after model optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjkye0LfIHMV",
        "outputId": "98f646ac-177b-44b8-daa2-1fdef46b0de7"
      },
      "source": [
        "#Calculate the RMSE on test data using the best set of parameters obtained after cross validation\n",
        "print(\"RMSE value after solving cold start problem is: \", evaluator.evaluate(best_model.transform(test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE value after solving cold start problem is:  0.9174356367648316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNw7bzwOMf4y"
      },
      "source": [
        "**The model performance has been improved by 0.32% after performing cross validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0-mPmvkGQsb"
      },
      "source": [
        "## **STEP 6**\n",
        "Output top 10 movies for all the users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiOInpSCVl9q"
      },
      "source": [
        "movie_rec = best_model.recommendForAllUsers(10)   #top 10 movie recommendations for all users\n",
        "#movie_rec.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCq2c5LJXgId"
      },
      "source": [
        "import pandas as pd\n",
        "movie_rec = movie_rec.toPandas()\n",
        "#movie_rec.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIRFva-CXrTT"
      },
      "source": [
        "users = []\n",
        "recommendations = []\n",
        "#For all data iterations\n",
        "for i in range(len(movie_rec)):\n",
        "\n",
        "  users.append(movie_rec.iloc[i,0])         #Add user_id to list\n",
        "  user_recs = \"\" \n",
        "\n",
        "  for item in movie_rec.iloc[i,1]:          #Fetching only the item ID's from the recommendations\n",
        "    user_recs = user_recs + \", \" + str(item.asDict()[\"item_id\"])\n",
        "  \n",
        "  recommendations.append(user_recs[2:])     #Append the itemID's to a list\n",
        "\n",
        "#Create a dataframe with the appended data\n",
        "recommendations_df = pd.DataFrame(data = zip(users, recommendations), columns=[\"UserID\", \"ItemID\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "obmMME6VXw6q",
        "outputId": "5c8d772e-88d9-4f9e-8b2c-44d8498f2d8a"
      },
      "source": [
        "#Displaying users and movie recommendations(top 10 movies) for the first 10 users\n",
        "recommendations_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>ItemID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>471</td>\n",
              "      <td>1233, 936, 1643, 1159, 1394, 909, 459, 1005, 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>463</td>\n",
              "      <td>1449, 6, 611, 408, 100, 958, 169, 114, 1512, 119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>833</td>\n",
              "      <td>179, 1463, 646, 32, 1367, 853, 320, 1558, 1187...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>496</td>\n",
              "      <td>320, 1467, 114, 42, 899, 1463, 190, 10, 61, 56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>148</td>\n",
              "      <td>169, 408, 921, 1167, 1449, 1019, 513, 745, 114...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>540</td>\n",
              "      <td>1398, 1449, 169, 1193, 316, 515, 408, 1122, 64...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>392</td>\n",
              "      <td>1463, 483, 318, 1643, 1449, 178, 963, 1142, 48...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>243</td>\n",
              "      <td>1449, 1193, 408, 1463, 1398, 483, 1643, 134, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>623</td>\n",
              "      <td>1463, 50, 483, 174, 1169, 478, 1449, 694, 659,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>737</td>\n",
              "      <td>1643, 127, 56, 1449, 60, 1142, 1558, 119, 156,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserID                                             ItemID\n",
              "0     471  1233, 936, 1643, 1159, 1394, 909, 459, 1005, 9...\n",
              "1     463   1449, 6, 611, 408, 100, 958, 169, 114, 1512, 119\n",
              "2     833  179, 1463, 646, 32, 1367, 853, 320, 1558, 1187...\n",
              "3     496     320, 1467, 114, 42, 899, 1463, 190, 10, 61, 56\n",
              "4     148  169, 408, 921, 1167, 1449, 1019, 513, 745, 114...\n",
              "5     540  1398, 1449, 169, 1193, 316, 515, 408, 1122, 64...\n",
              "6     392  1463, 483, 318, 1643, 1449, 178, 963, 1142, 48...\n",
              "7     243  1449, 1193, 408, 1463, 1398, 483, 1643, 134, 2...\n",
              "8     623  1463, 50, 483, 174, 1169, 478, 1449, 694, 659,...\n",
              "9     737  1643, 127, 56, 1449, 60, 1142, 1558, 119, 156,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDFeojdfX7ow"
      },
      "source": [
        "#write to a text file\n",
        "recommendations_df.to_csv('/content/drive/Shared drives/IDS561/HW5/recommendation_output.txt', sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}